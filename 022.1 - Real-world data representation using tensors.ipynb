{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "701d2295-c7e9-4c84-8fe1-483e203c1b0d",
   "metadata": {},
   "source": [
    "# Day 22 - Real-world data representation using tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803ce949-03df-483f-8679-f03404adaa32",
   "metadata": {},
   "source": [
    "## Working with time series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e592658c-024a-4d1c-8fbc-27aab0ad87c2",
   "metadata": {},
   "source": [
    "### Shaping the data by time period\n",
    "\n",
    "* We can reshape this data into $N$ (days) collections of $C$ (columns) of length $L$ (hours)\n",
    "* Here, $C$ represents our different variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "922aab99-d94a-4665-8eca-63f85949635e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 3.0000e+00, 1.3000e+01,\n",
       "         1.6000e+01],\n",
       "        [2.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 8.0000e+00, 3.2000e+01,\n",
       "         4.0000e+01],\n",
       "        [3.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 5.0000e+00, 2.7000e+01,\n",
       "         3.2000e+01],\n",
       "        ...,\n",
       "        [1.7377e+04, 3.1000e+01, 1.0000e+00,  ..., 7.0000e+00, 8.3000e+01,\n",
       "         9.0000e+01],\n",
       "        [1.7378e+04, 3.1000e+01, 1.0000e+00,  ..., 1.3000e+01, 4.8000e+01,\n",
       "         6.1000e+01],\n",
       "        [1.7379e+04, 3.1000e+01, 1.0000e+00,  ..., 1.2000e+01, 3.7000e+01,\n",
       "         4.9000e+01]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "bikes_numpy = np.loadtxt(\n",
    "    \"./DLPT/data/bike-sharing-dataset/hour-fixed.csv\",\n",
    "    dtype=np.float32,\n",
    "    delimiter=\",\",\n",
    "    skiprows=1,\n",
    "    converters={1: lambda x: float(x[8:10])}\n",
    ")\n",
    "bikes = torch.from_numpy(bikes_numpy)\n",
    "\n",
    "bikes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb2dc41-eb35-4cd0-9de9-56fe37c49b52",
   "metadata": {},
   "source": [
    "* To reshape our data, we just have to get a new view over it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d2de454-0be7-4d98-86ae-bee9da49dea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([17520, 17]), (17, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.shape, bikes.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e81443-1ffd-4509-b742-3a179494e71e",
   "metadata": {},
   "source": [
    "* If we want to reshape this into 24-hour chunks, then we need the stride along the $N$ dimension to be $24\\times17=408$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73b1b99b-368d-404b-a91b-f7fd2c2c0f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([730, 24, 17]), (408, 17, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes = bikes.view(-1, 24, bikes.shape[1])\n",
    "\n",
    "daily_bikes.shape, daily_bikes.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4f2487-5248-4029-ba9f-3f4216dc4f32",
   "metadata": {},
   "source": [
    "* To get the correct shape, we now have to swap the rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ae4133b-4d54-429f-9fad-ae06c1a955c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([730, 17, 24]), (408, 1, 17))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes = daily_bikes.transpose(1, 2)\n",
    "\n",
    "daily_bikes.shape, daily_bikes.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966b0013-8b17-4e4f-95cf-76c559f290a2",
   "metadata": {},
   "source": [
    "### Ready for training\n",
    "\n",
    "* The `weathersit` variable is ordinal, but has no meaningful ordering, so we should turn it into a one-hot representation\n",
    "* Let's initialize a tensor to represent the first day's weather situation at each hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3783955d-ffe2-4ead-97c7-00aa906fc47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_day = bikes[:24].long()\n",
    "weather_onehot = torch.zeros(first_day.shape[0], 4)\n",
    "\n",
    "first_day[:, 9] # 9 is the index of the `weathersit` variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ae7dae-908e-433c-9f33-182d15ea9cca",
   "metadata": {},
   "source": [
    "* Now we `scatter` these indices into our matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ace1b1d0-d2c2-4a10-ae02-69ed1513b2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_onehot.scatter_(\n",
    "    dim=1,\n",
    "    index=first_day[:, 9].unsqueeze(1).long() - 1,\n",
    "    value=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf66bd03-e963-4705-b93c-026bcf0bef97",
   "metadata": {},
   "source": [
    "* We can now con`cat`enate this data to the first 24 hours of the bike data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53b19e17-66ee-4557-a8e0-f6028525ece3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  1.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  6.0000,\n",
       "          0.0000,  1.0000,  0.2400,  0.2879,  0.8100,  0.0000,  3.0000, 13.0000,\n",
       "         16.0000,  1.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((bikes[:24], weather_onehot), 1)[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6372b69-2474-4e2b-9510-ade419a2ae0f",
   "metadata": {},
   "source": [
    "* The final four columns are now the one-hot representation of `weathersit`\n",
    "* Let's apply this to our `daily_bikes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6037e4a1-5969-4091-ab88-5bed6c003139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([730, 4, 24])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_onehot = torch.zeros(daily_bikes.shape[0], 4,\n",
    "                                   daily_bikes.shape[2])\n",
    "\n",
    "daily_weather_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ac58685-19d7-4e6b-91fc-f595d8a24671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([730, 4, 24])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_onehot.scatter_(\n",
    "    dim=1,\n",
    "    index=daily_bikes[:, 9, :].unsqueeze(1).long() - 1,\n",
    "    value=1.0,\n",
    ")\n",
    "daily_weather_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5531cb2-96dc-412d-9f73-a88d1a391e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_bikes = torch.cat((daily_bikes, daily_weather_onehot), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85e3382-cf0d-4fa7-821d-22139d7eb758",
   "metadata": {},
   "source": [
    "* An alternative to this one-hot representation is to pretend it's a continuous variable, which goes up as the weather worsens\n",
    "* We can transform it into a float ranging from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7107e166-4e9f-4346-93f6-e08b7daf69f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_bikes[:, 9, :] = (daily_bikes[:, 9, :] - 1.0) / 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718d1645-24e5-42ce-884f-cc2fd88a2044",
   "metadata": {},
   "source": [
    "* Aside from this simple method of mapping the variables from 0 to 1, we could also subtract their mean and divide by their standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2062aca5-9e16-47c3-83d3-3ef168f6cea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = daily_bikes[:, 10, :]\n",
    "temp_mean = torch.mean(temp)\n",
    "temp_std = torch.std(temp)\n",
    "\n",
    "daily_bikes[:, 10, :] = (temp - temp_mean) / temp_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6093e892-fde8-478b-9930-4ed21cb790c8",
   "metadata": {},
   "source": [
    "* This variable will then have zero mean and unitary standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480a0c50-8826-4dc7-b49e-ce2a13ba6d69",
   "metadata": {},
   "source": [
    "## Representing text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450f46ab-1a38-45f9-8dbe-89670079c751",
   "metadata": {},
   "source": [
    "### Converting text to numbers\n",
    "\n",
    "* Two great sources of text data are [Project Gutenberg](https://gutenberg.org) and [English Corpora](https://english-corpora.org)\n",
    "* There's even a Wikipedia corpus available\n",
    "* For now, let's get started with Jane Austen's [Pride and Prejudice](http://www.gutenberg.org/files/1342/1342-0.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a33befd-cd15-41a8-bfd1-4ea97f751e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./DLPT/data/text/pride_and_prejudice.txt\"\n",
    "with open(data_path, \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f296df0c-0182-4c98-8a34-ad635f82ec82",
   "metadata": {},
   "source": [
    "### One-hot-encoding characters\n",
    "\n",
    "* Frist, we split the text into lines, and pick an arbitrary line to focus on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14f7d18f-7e0b-4158-9a3c-4648c1919055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“Impossible, Mr. Bennet, impossible, when I am not acquainted with him'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = text.split('\\n')\n",
    "line = lines[855]\n",
    "line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4f77eb-e5de-43a0-a6af-04d176686c80",
   "metadata": {},
   "source": [
    "* Let's create a tensor that can hold the one-hot encoding of each character of the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9ed3460-84da-4f0d-81d4-ad67a9c06343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70, 128])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter_t = torch.zeros(len(line), 128)\n",
    "letter_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f98b20b-a600-4d7d-988c-f509e33f8b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, letter in enumerate(line.lower().strip()):\n",
    "    letter_index = ord(letter) if ord(letter) < 128 else 0\n",
    "    letter_t[i][letter_index] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5843e43e-c768-4bd9-89b9-34e9c350032a",
   "metadata": {},
   "source": [
    "### One-hot encoding whole words\n",
    "\n",
    "* To one-hot encode whole words, we first need to collect our vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b678055a-a009-4039-b577-f10df2756457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_words(input_str):\n",
    "    punctuation = '.,;:\"?!”“_-'\n",
    "    word_list = input_str.lower().replace(\"\\n\", \" \").split()\n",
    "    return [word.strip(punctuation) for word in word_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f2d5966-360d-4475-86ff-91b1f60b72ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('“Impossible, Mr. Bennet, impossible, when I am not acquainted with him',\n",
       " ['impossible',\n",
       "  'mr',\n",
       "  'bennet',\n",
       "  'impossible',\n",
       "  'when',\n",
       "  'i',\n",
       "  'am',\n",
       "  'not',\n",
       "  'acquainted',\n",
       "  'with',\n",
       "  'him'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_line = clean_words(line)\n",
    "line, words_in_line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eec629-69c0-4a55-9c1d-377e57ee1cf1",
   "metadata": {},
   "source": [
    "* We can now create a vocabulary of our whole text, and assign each word to an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e38c019-b8a7-4e7a-a7f5-4fb6697a67a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7465, 3455)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = sorted(set(clean_words(text)))\n",
    "word2index_dict = {word: i for i, word in enumerate(word_list)}\n",
    "\n",
    "len(word2index_dict), word2index_dict[\"impossible\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf4c255-71c0-451d-9110-ccd82847af74",
   "metadata": {},
   "source": [
    "* We can now one-hot encode our line, using this `word2index_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "689b0474-0ae3-4393-abc4-04e427cf8b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 3455 impossible\n",
      " 1 4394 mr\n",
      " 2  807 bennet\n",
      " 3 3455 impossible\n",
      " 4 7221 when\n",
      " 5 3370 i\n",
      " 6  408 am\n",
      " 7 4529 not\n",
      " 8  222 acquainted\n",
      " 9 7291 with\n",
      "10 3273 him\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 7465])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_t = torch.zeros(len(words_in_line), len(word2index_dict))\n",
    "for i, word in enumerate(words_in_line):\n",
    "    word_index = word2index_dict[word]\n",
    "    word_t[i][word_index] = 1\n",
    "    print(f\"{i:2} {word_index:4} {word}\")\n",
    "\n",
    "word_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24b1c58-d2b1-43b8-9afe-e96961228332",
   "metadata": {},
   "source": [
    "* One intermediate representation between encoding characters and whole words is called $byte\\ pair\\ encoding$\n",
    "* This starts with a dictionary of individual letters, but then adds the most common pairs of items until it reaches the prescribed dictionary size\n",
    "* This may lead to a tokenization of our sentence that looks like this:\n",
    "\n",
    "      ▁Im|pos|s|ible|,|▁Mr|.|▁B|en|net|,|▁impossible|,|▁when|▁I|▁am|▁not|▁acquainted|▁with|▁him"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1edfc07-32b1-4a04-8579-eb95a9a7f747",
   "metadata": {},
   "source": [
    "### Text embeddings\n",
    "\n",
    "* These one-hot ecodings quickly become unwieldy for large vocabularies\n",
    "* It would be great if we could compress them\n",
    "* To do so, we could turn them from thousands of zeros and a single one into a couple hundred floating point numbers\n",
    "* This is called an embedding, and useful ways of embedding similar words near each other can be learned by neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33966d9-ebf5-441e-aca1-a41f311e0ca3",
   "metadata": {},
   "source": [
    "### Text embeddings as a blueprint\n",
    "\n",
    "* Embeddings are useful as soon as one-hot encoding becomes too cumbersome\n",
    "* This can be the case even for non-textual, categorical data\n",
    "* It is common to improve the prelearned embeddings while solving the problem at hand\n",
    "* The techniques developed for natural language processing can often serve as inspiration, as blueprints, for preocessing of other sequential data, like embeddings being used for non-textual data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278db5bb-8e5e-43eb-a99f-ed139ccd8167",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a45bf8c-0f63-4dec-b8db-f4c975316178",
   "metadata": {},
   "source": [
    "1. Take several pictures of red, blue, and green items with your phone or other digital camera (or download some from the internet, if a camera isn’t available).\n",
    "    1. Load each image, and convert it to a tensor.\n",
    "    1. For each image tensor, use the .mean() method to get a sense of how bright the image is.\n",
    "    1. Take the mean of each channel of your images. Can you identify the red, green, and blue items from only the channel averages?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004b9f01-6b3f-468d-af14-8ace528d6be3",
   "metadata": {},
   "source": [
    "No."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbe4754-5086-4c15-b772-c3c5c6468aa2",
   "metadata": {},
   "source": [
    "2. Select a relatively large file containing Python source code.\n",
    "    1. Build an index of all the words in the source file (feel free to make your tokenization as simple or as complex as you like; we suggest starting with replacing `r\"[^a-zA-Z0-9_]+\"` with spaces).\n",
    "    1. Compare your index with the one we made for Pride and Prejudice. Which is larger?\n",
    "    1. Create the one-hot encoding for the source code file.\n",
    "    1. What information is lost with this encoding? How does that information compare to what’s lost in the Pride and Prejudice encoding?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00abc805-333e-4810-a428-6b97c4907260",
   "metadata": {},
   "source": [
    "No."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
