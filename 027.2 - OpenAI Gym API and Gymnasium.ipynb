{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3ce6e85-164a-4e06-af9c-d64477dfb782",
   "metadata": {},
   "source": [
    "# Day 27 - OpenAI Gym API and Gymnasium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e928c2e7-18a1-44eb-bf1d-6c0b8d5d842d",
   "metadata": {},
   "source": [
    "## The anatomy of the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc5c091e-4399-43b5-b0e5-1f22b89259ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdc8175e-fd68-4052-b198-42f4d8e44a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self):\n",
    "        self.steps_left = 10\n",
    "\n",
    "    def get_observation(self) -> List[float]:\n",
    "        return [0.0, 0.0, 0.0]\n",
    "\n",
    "    def get_actions(self) -> List[int]:\n",
    "        return [0, 1]\n",
    "\n",
    "    def is_done(self) -> bool:\n",
    "        return self.steps_left == 0\n",
    "\n",
    "    def action(self, action: int) -> float:\n",
    "        if self.is_done():\n",
    "            raise Exception(\"Game is over\")\n",
    "        self.steps_left -= 1\n",
    "        return random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae959c0d-f700-4ca9-8d92-d7369a104347",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.total_reward = 0.0\n",
    "\n",
    "    def step(self, env: Environment):\n",
    "        current_obs = env.get_observation()\n",
    "        actions = env.get_actions()\n",
    "        reward = env.action(random.choice(actions))\n",
    "        self.total_reward += reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9519c763-f968-49b3-9bcc-47c602638b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward got: 6.0649\n"
     ]
    }
   ],
   "source": [
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "while not env.is_done():\n",
    "    agent.step(env)\n",
    "    \n",
    "print(f\"Total reward got: {agent.total_reward:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f479c2a1-1429-4839-b47a-f51ce4c5bd85",
   "metadata": {},
   "source": [
    "## The OpenAI Gym API and Gymnasium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db71e20-b6e4-477e-810b-cab196070683",
   "metadata": {},
   "source": [
    "### The action space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ce8239-230d-4806-acb4-ddb59de44ec7",
   "metadata": {},
   "source": [
    "### The observation space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff35004-7c4b-4abc-b1c9-6eef904570d4",
   "metadata": {},
   "source": [
    "* Gymnasium's `Space`s include one property, and three methods that are important to us:\n",
    "    0. `shape`: Just like a NumPy shape\n",
    "    0. `sample()`: Returns a random sample from the space\n",
    "    0. `contains(x)`: Returns true if `x` is part of the space\n",
    "    0. `seed()`: For reproducible runs\n",
    "* Here are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f714167-9d87-4e05-8847-f970ba18813b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tuple(Box(-1.0, 1.0, (3,), float32), Discrete(3), Discrete(2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Tuple, Box, Discrete\n",
    "\n",
    "Tuple(spaces=(\n",
    "    Box(low=-1.0, high=1.0, shape=(3,), dtype=np.float32),\n",
    "    Discrete(n=3),\n",
    "    Discrete(n=2),\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58e7be1-ae4d-4f8b-a317-24269c17e9bd",
   "metadata": {},
   "source": [
    "### The environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6d0017-f7a2-4488-9163-f25cf8237f5a",
   "metadata": {},
   "source": [
    "* An environment—the `Env` class in Gymnasium—has an `action_space`, an `observation_space`, a `reset()` method, and a `step()` method\n",
    "* The latter returns `obs, reward, done, truncated, info`\n",
    "    * Here, `info` is a dictionary with optional information that the environment can include"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712ea119-7c47-4d0c-b7f1-5ec74d70bab5",
   "metadata": {},
   "source": [
    "### Creating an environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38f03e5-84be-440d-87bc-3a1125ee8bea",
   "metadata": {},
   "source": [
    "* To create an environment, Gymnasium provides the `make` method, which takes as its only argument the id of an environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911b4f62-af9d-4470-a4e7-b03bbd4f8cbc",
   "metadata": {},
   "source": [
    "### The CartPole session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4b9bdcd-988d-46bf-adcc-c0985ac2ec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed6a82ae-af5e-425c-8e5f-0b58e7fceb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.03194962, -0.04086227, -0.0243945 ,  0.01727769], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs, info = e.reset()\n",
    "obs, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "431e7392-542e-49b8-a93e-9c7cf92c77ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Discrete(2),\n",
       " Box([-4.8               -inf -0.41887903        -inf], [4.8               inf 0.41887903        inf], (4,), float32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.action_space, e.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e11ef9e-9407-4b46-855a-8b546ae2253a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.03276687, -0.23562603, -0.02404895,  0.30216515], dtype=float32),\n",
       " 1.0,\n",
       " False,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46bcfc39-386c-41d0-98c4-9fd388d41c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, array([2.2864687 , 0.26136494, 0.24771014, 0.39573586], dtype=float32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.action_space.sample(), e.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da68ac4b-0874-4100-8848-a03c6ce1d1a2",
   "metadata": {},
   "source": [
    "## The random CartPole agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04397cdb-5755-44ea-bfa6-a4baeff901f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de34998d-3212-4811-b9da-4c07fd28a801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_episode(env):\n",
    "    total_steps = 0\n",
    "    total_reward = 0.0\n",
    "    obs, _ = env.reset()\n",
    "    \n",
    "    while True:\n",
    "        action = env.action_space.sample()\n",
    "        _, reward, done, *_ = env.step(action)\n",
    "        total_reward += reward\n",
    "        total_steps += 1\n",
    "        if done:\n",
    "            break\n",
    "    return total_steps, total_reward    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cf33fd9-8a31-4007-a3ee-a6bcdde197ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average episode done in 22.76 steps. Average return: 22.76.\n"
     ]
    }
   ],
   "source": [
    "episodes = [random_episode(env) for e in range(500)]\n",
    "steps, returns = [], []\n",
    "for s, ret in episodes:\n",
    "    steps.append(s)\n",
    "    returns.append(ret)\n",
    "\n",
    "average_steps = np.mean(steps)\n",
    "average_return = np.mean(returns)\n",
    "\n",
    "print(f\"Average episode done in {average_steps:.2f} steps. Average return: {average_return:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816da209-16d2-4b9a-a85f-ae132cc2c22a",
   "metadata": {},
   "source": [
    "## Extra Gym API functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab33f6fa-1130-487a-85fb-44c3e2d4cf20",
   "metadata": {},
   "source": [
    "### Wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bb2f78-0785-474e-874c-417fe8898097",
   "metadata": {},
   "source": [
    "* As it is often convenient to transform the observations, keep track of the last $n$ frames, or perform steps like reward normalization, Gymnasium providesa `Wrapper` class to wrap environments\n",
    "* For convenience, there are to properties:\n",
    "    1. `env`, which is the environment being wrapped by this wrapper\n",
    "    2. `unwrapped`, which is the base environment at the center of all wrappers\n",
    "* There also exist `ObservationWrapper`, `RewardWrapper`, and `ActionWrapper` classes\n",
    "* These allow selective wrapping, requiring the overriding of the `observation(obs)`, `reward(rew)`, and `action(a)` methods respectively\n",
    "* As an example, this wrapper makes any agent epsilon-greedy with $\\varepsilon=0.1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec0227ab-ddfc-45ae-b7f2-c04fc9ee9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomActionWrapper(gym.ActionWrapper):\n",
    "    def __init__(self, env: gym.Env, epsilon: float = 0.1):\n",
    "        super().__init__(env)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def action(self, action: gym.core.WrapperActType) -> gym.core.WrapperActType:\n",
    "        if random.random() < self.epsilon:\n",
    "            action = self.env.action_space.sample()\n",
    "            print(f\"Random action: {action}\")\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6befa348-b269-4a0a-87a1-a8fb229e8dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random action: 1\n",
      "Random action: 0\n",
      "Random action: 1\n",
      "Random action: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(52, 52.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = RandomActionWrapper(gym.make(\"CartPole-v1\"))\n",
    "random_episode(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39917927-f9ee-4aeb-8ef6-e052eb48d39f",
   "metadata": {},
   "source": [
    "### Rendering the environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f7b33ab-6ad6-4270-94ea-b0574f160e2e",
   "metadata": {},
   "source": [
    "* The way I run Juypter, the code below will not work\n",
    "```python \n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "env = gym.wrappers.HumanRendering(env)\n",
    "random_episode(env)\n",
    "```\n",
    "* Instead, we will skip to recording a video and displaying it in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d537d5d-cd0c-4f05-a9e4-c86f36223e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_folder = \"./DRL/videos/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdcb08b4-8ba9-4369-b05e-7fb836266efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', message='.*Overwriting existing videos.*')\n",
    "\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "env = gym.wrappers.RecordVideo(env, video_folder=video_folder)\n",
    "random_episode(env)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2729600-dd8c-4b39-bb02-a236cb35f362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"./DRL/videos/rl-video-episode-1.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(video_folder + \"rl-video-episode-1.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
