{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce501c2-068a-48ef-b8ae-c74ed2e98e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2e07eb-edc1-411d-be35-471236d7d595",
   "metadata": {},
   "source": [
    "# Day 18 - It starts with a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352bc3fe-9eac-4f19-9828-18ab7fa0ee79",
   "metadata": {},
   "source": [
    "## The tensor API\n",
    "\n",
    "* Most operations can also be called as exactly equivalent tensor methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b5ec6fb-825a-4bd7-b70c-89b93b7755e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.ones(3, 2)\n",
    "a_t = torch.transpose(a, 0, 1)\n",
    "\n",
    "a.shape, a_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c983425f-dad3-4dce-ae7e-8a7ca1b7143b",
   "metadata": {},
   "source": [
    "* This is equivalent to the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91d4a9d0-da15-4d66-b9a8-4f41f22ac734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3, 2)\n",
    "a_t = a.transpose(0, 1)\n",
    "\n",
    "a.shape, a_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f539c037-503d-4741-ae01-a50714d5148b",
   "metadata": {},
   "source": [
    "* The [online docs](http://pytorch.org/docs) are exhaustive, and group the operations\n",
    "* Creation (`zeros`, `ones`, ...)\n",
    "* Indexing, slicing mutating (`transpose`, ...)\n",
    "* Math\n",
    "    * Pointwise\n",
    "    * Reduction\n",
    "    * Comparison\n",
    "    * Spectral (frequencies)\n",
    "    * Other special functions\n",
    "    * BLAS and LAPACK, standardized linear algebra operations\n",
    "* Random sampling\n",
    "* Serializtion\n",
    "* Parallelism (setting parameters, eg. `set_num_threads`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6588ca57-dcd1-45bf-a22d-1c365115ca50",
   "metadata": {},
   "source": [
    "## Tensors: Scenic views of storage\n",
    "\n",
    "* The values are stored in a `torch.Storage`, which holds a 1D, contiguous chunk of memory\n",
    "* Actual `torch.Tensor`s are views over this storage\n",
    "* Each tensor can have different offsets and per-dimension strides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd67db8-a418-4a04-a42a-b907dd56d157",
   "metadata": {},
   "source": [
    "### Indexing into storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df66056e-6d77-43be-9dd4-98da3f797796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 1.0\n",
       " 5.0\n",
       " 3.0\n",
       " 2.0\n",
       " 1.0\n",
       "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points.storage() # This is depracated, and untyped_storage should be used instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21a01f62-99fe-4484-a21f-245035720193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_storage = points.storage()\n",
    "points_storage[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0dcae03-d253-4d36-bb6f-25bac6dde9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.storage()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ba5647-64c9-40eb-91b7-6ed2658bf6ee",
   "metadata": {},
   "source": [
    "* Of course, changing the underlying storage will also change what a tensor views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1722748c-22a2-454f-bf75-0c858be6febe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_storage[0] = 2.0\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a08a0ed2-a282-4940-acba-0e54ef9fc5fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       "[torch.storage.UntypedStorage(device=cpu) of size 8]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bools = torch.tensor([[True, False], [False, False], [False, True], [True, True]])\n",
    "bools.untyped_storage() # <- Just one byte!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a76c09-15fd-4d6b-9424-a02b72fa2e1d",
   "metadata": {},
   "source": [
    "### Modifying stored values: In-place operations\n",
    "\n",
    "* Some operations are only available as methods on `Tensor` objects\n",
    "* These are identified by their trailing undescores, like `zero_()`\n",
    "* They are *in-place* operations, modifying the underlying data\n",
    "* Thus, they do not create and return a new tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f51ef12-602b-4fe2-8f8b-b0e2f28299ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3, 2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72257a22-1f96-489b-b46c-1d35b8e291fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.zero_()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a58023d-6791-4248-a3da-fec6fd26e563",
   "metadata": {},
   "source": [
    "## Tensor metadata: Size, offset, and stride\n",
    "\n",
    "* A tensor is fully defined by storage, size, offset and stride\n",
    "* Size is a tuple, indicating the number of elements along each dimension\n",
    "* Offset is the index of the tensor's first element in the underlying storage\n",
    "* Stride is the number of elements that need to be skipped to get to the next element in each dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caedd2b-01fa-4d76-abd2-5e430acd5dca",
   "metadata": {},
   "source": [
    "### Views of another tensor's storage\n",
    "\n",
    "* To access the second point, the offset has to be 2, as the first two elements of the storage have to be skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de034dde-14bd-489f-aa08-37b9f7f5f7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "second_point = points[1]\n",
    "second_point.storage_offset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2821d29-5ab8-4eb9-8de8-1c11fe64daab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2]), torch.Size([2]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.size(), second_point.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6674d255-f7af-4ab2-9045-be59191c9921",
   "metadata": {},
   "source": [
    "* Two elements have to be skipped to get to the next point\n",
    "* One element has to be skipped to get to the next coordinate of a point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcb522a8-3247-4bfa-822d-188960fd7508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6861c35c-83c4-48da-83ba-9e2aebc8ae57",
   "metadata": {},
   "source": [
    "* Accessing the element at `i, j`, we retrieve `storage_offset + i * stride[0] + j * stride[1]`\n",
    "* Defining a tensor like this makes many operations cheap, by simply allocating a new tensor with different size, offset, and stride, viewing the same underlying memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0efa07d-405a-4559-b314-6f7368c5bd0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2]), 2, (1,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point = points[1]\n",
    "second_point.size(), second_point.storage_offset(), second_point.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c38d2a-947e-4f08-aa4f-95804e534847",
   "metadata": {},
   "source": [
    "* Sometimes, we want to modify the tensor, without changing the original data\n",
    "* In order to do this, we can clone the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36a4dc2b-fdd6-41e1-a6ee-7f5f5e188062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "second_point = points[1].clone()\n",
    "second_point[0] = 10.0\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13faaaba-5034-4183-98b1-b1a0bf4b69f0",
   "metadata": {},
   "source": [
    "### Transposing without copying\n",
    "\n",
    "* The `t` function is a shorthand for `transpose`-ing a two-dimensional tensor\n",
    "* This allows us, for example, to turn our points array from one where each row represents a point, to one where each column represents a point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c186a70f-311b-4b3f-825c-5d1d5bf5a8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ba699ca-967b-4bec-8845-b5f7922ad257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t = points.t()\n",
    "points_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a215439-4a29-4f7f-ace4-72115d3f3951",
   "metadata": {},
   "source": [
    "* These share the same untyped storage, but differ in their properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd5dbb70-5ccb-443c-ad34-8d873a51629d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(points.untyped_storage()) == id(points_t.untyped_storage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62a2d94a-0d21-489d-ae2f-d45abbe66761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 1), (1, 2))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.stride(), points_t.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83ec2ee-35e3-4811-ae88-bebcec68a09e",
   "metadata": {},
   "source": [
    "* Transposing is simply flipping the shape and stride of the tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca00a2ec-0d2f-43fd-b67a-7643dd7190aa",
   "metadata": {},
   "source": [
    "### Transposing in higher dimensions\n",
    "\n",
    "* To transpose in higher dimensions, we just have to specify the dimensions along which to flip the shape and stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80c72780-710e-4f2b-aebe-60b7c9acc96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4, 5]), torch.Size([5, 4, 3]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_t = torch.ones(3, 4, 5)\n",
    "transpose_t = some_t.transpose(0, 2)\n",
    "some_t.shape, transpose_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "635cdb25-2b30-436f-afde-eb80055f1339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 5, 1), (1, 5, 20))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_t.stride(), transpose_t.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f25e32-7e45-417c-92e3-016d92bd6452",
   "metadata": {},
   "source": [
    "* A tensor that is laid out in memory starting from the rightmost dimension onward can be efficiently visited element by element, as it is `contiguous`\n",
    "* This locality can provide the best performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07834558-a701-4648-aedf-3af796f4b1ef",
   "metadata": {},
   "source": [
    "### Contiguous tensors\n",
    "\n",
    "* Some operations work only on contiguous tensors\n",
    "* Trying to use these will inform us to use `contiguous`, which costs nothing if the tensor already is contiguous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d67217c2-cb55-482c-aeeb-15b3b735cd2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.is_contiguous(), points_t.is_contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51403eed-afff-4a46-8fd1-d3a5bd2ba29c",
   "metadata": {},
   "source": [
    "* To obtain a contiguous tensor from a non-contiguous one, the `contiguous` method will change the stride, as well as the underlying storage to match it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db2f3c9a-e05e-4058-8cf7-72f2be346624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4., 5., 2.],\n",
       "         [1., 3., 1.]]),\n",
       " (1, 2),\n",
       "  4.0\n",
       "  1.0\n",
       "  5.0\n",
       "  3.0\n",
       "  2.0\n",
       "  1.0\n",
       " [torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points_t = points.t()\n",
    "points_t, points_t.stride(), points_t.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92098dea-df8f-4344-842a-0b8c63ce599e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4., 5., 2.],\n",
       "         [1., 3., 1.]]),\n",
       " (3, 1),\n",
       "  4.0\n",
       "  5.0\n",
       "  2.0\n",
       "  1.0\n",
       "  3.0\n",
       "  1.0\n",
       " [torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t_cont = points_t.contiguous()\n",
    "points_t_cont, points_t_cont.stride(), points_t_cont.storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee6a64e-e456-4292-9c68-429497e1e412",
   "metadata": {},
   "source": [
    "* Essentially, transposing changes the view, while making a transpose `contiguous` changes the underlying storage to match the original stride"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a735ea7-370b-41da-8ed3-5debdb1e858f",
   "metadata": {},
   "source": [
    "## Moving tensors to the GPU\n",
    "\n",
    "* PyTorch provides hardware acceleration not just with CUDA, but also ROCm, or Google TPUs and Intel's XPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7777da-ef41-4d3e-b4b7-29bc1241c11d",
   "metadata": {},
   "source": [
    "### Managing a tensor's device attribute\n",
    "\n",
    "* In addition to `dtype`, a tensor also has a `device` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "223adf5c-0563-4505-b49c-6a807473d2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e19d71-8dce-401b-a719-f62645eb559a",
   "metadata": {},
   "source": [
    "* Aside from specifying it during creation, a tensor can be moved `to` a different device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a03db17e-3ef6-4c72-b344-0be0dcd05f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = points.to(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d8381-8b33-4e79-9d39-f95064289e46",
   "metadata": {},
   "source": [
    "* With multiple GPUs, they can be directly indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c907cbbc-6edd-4962-b15d-048bd53efeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = points.to(device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b0078b-ff56-46e5-a574-ae1166f43e70",
   "metadata": {},
   "source": [
    "* Moving it back to the CPU works the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13a25518-f5f1-4402-a913-0242d05d7470",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_cpu = points_gpu.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41782493-0426-47fd-892f-a12716ecfbcb",
   "metadata": {},
   "source": [
    "* There are shorthand methods for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2e07748-10a1-46d6-9c9d-bc1180110ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = points.cuda()\n",
    "points_gpu = points.cuda(0)\n",
    "points_cpu = points_gpu.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aae652-6134-4f73-a6c3-5e5de183d7b8",
   "metadata": {},
   "source": [
    "## NumPy interoperability\n",
    "\n",
    "* Conversion between NumPy's `ndarray`s and PyTorch's `tensor`s is zero-copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb75e2a9-1c7d-47fa-bfa4-a7552725ab15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.ones(3, 4)\n",
    "points_np = points.numpy()\n",
    "points_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663f0ae8-9f58-48fd-8930-980758789998",
   "metadata": {},
   "source": [
    "* As long as the data is stored in CPU RAM, this operation is effectively no cost, as the NumPy array shares the same underlying memory\n",
    "* There is of course also an operation that does the reverse\n",
    "* Note that NumPy's default type is `float64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1934759-879c-4ccd-bf49-84afb910c8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "points_np_fresh = np.ones((3, 4))\n",
    "\n",
    "points = torch.from_numpy(points_np)\n",
    "points_fresh = torch.from_numpy(points_np_fresh)\n",
    "\n",
    "points.dtype, points_fresh.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c2b0b6-e6b6-4338-b8b8-66b870fc70ed",
   "metadata": {},
   "source": [
    "## Generalized tensors are tensors, too\n",
    "\n",
    "* Anything that fulfills the `tensor` API can be considered a tensor\n",
    "* There are specialized tensor types, for example for different hardware\n",
    "* One type is the sparse tensor, which stores only nonzero elements and index information\n",
    "* The $dispatching$ mechanism finds the correct operation to perform on whatever the underlying data is\n",
    "* Later, we meet $quantized$ tensors, which are different from the $dense$, or $strided$ tensors that we already know\n",
    "* The number of kinds of tensors has been growing steadily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9b5f81-b2fc-4fcd-a3cb-d9624ebd9de0",
   "metadata": {},
   "source": [
    "## Serializing tensors\n",
    "\n",
    "* To store tensors in a file, PyTorch uses `pickle` under the hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bfe929a-0f59-4d3a-941c-ad5c3afe4bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(points, \"./DLPT/data/ourpoints.t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ef3672f-7a83-4c5c-94e7-8110bad286ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./DLPT/data/ourpoints.t\", \"wb\") as f:\n",
    "    torch.save(points, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dfd7b555-7f54-4dfe-b3e0-07fe9d1a537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.load(\"./DLPT/data/ourpoints.t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c731acdc-298c-4fb9-acee-24034e3fc90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./DLPT/data/ourpoints.t\", \"rb\") as f:\n",
    "    points = torch.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557143a1-bbc1-49c6-9639-c2c99827e599",
   "metadata": {},
   "source": [
    "* This file format is not interoperable, and can generally only be read by PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a824522-6f68-4690-92f0-073a6f244e6f",
   "metadata": {},
   "source": [
    "### Serializing to HDF5 with h5py\n",
    "\n",
    "* When interoperability is needed, tensors can be stored in the HDF5 format\n",
    "* This is achieved with the `h5py` library, after converting to a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2cffd95c-2039-4a77-85d0-9bd599dbd36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "f = h5py.File(\"./DLPT/data/ourpoints.hdf5\", \"w\")\n",
    "dset = f.create_dataset(\"coords\", data=points.numpy())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b75929-94a7-4a98-ae6e-62d6bf791b47",
   "metadata": {},
   "source": [
    "* Here, `\"coords\"` is the key into the HDF5 file\n",
    "* We can use other keys as well, and we can index into the file while it's on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a304ab50-b8d2-4ab1-aa48-72259cc4d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"./DLPT/data/ourpoints.hdf5\", \"r\")\n",
    "dset = f[\"coords\"]\n",
    "last_points = dset[-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddef54ae-0815-45b5-84ce-2128caec12d2",
   "metadata": {},
   "source": [
    "* The data is only read from disk once we index into it by asking for `[-2:]`\n",
    "* The returned object is a NumPy-like array with the same API, allowing us to use `torch.from_numpy`\n",
    "* This then copies the data into a PyTorch `Storage`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1a5f3a7-0d7b-48c1-88d7-3143577dbc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_points = torch.from_numpy(dset[-2:])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b374114-f330-418b-a3b8-be6b233b53f5",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "* We have learned everything we need to represent all of our data in floats\n",
    "* other aspects, like creating views, indexing tensors with other tensors, and broadcasting, are covered later as need arises\n",
    "* In the next chapter, we will represent real-world data with tensors\n",
    "    * We start off with tabular data\n",
    "    * But we will also move on to something more elaborate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91e120a-3875-455a-8d68-d535ceeb299e",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Create a tensor `a` from `list(range(9))`. Predict and then check the size, offset, and stride.\n",
    "    1. Create a new tensor using `b = a.view(3, 3)`. What does view do? Check that `a` and `b` share the same storage.\n",
    "    2. Create a tensor `c = b[1:, 1:]`. Predict and then check the size, offset, and stride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1265125b-fb94-4856-b273-dd739deacd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(list(range(9)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72d446e-73e4-4592-bb44-c6efdcf91ed0",
   "metadata": {},
   "source": [
    "The size should be `[9]`, the offset `0`, and the stride `[1]`. (Nope! This is a tuple.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06e86198-706b-4335-9e93-92fb0914ae65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9]), 0, (1,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size(), a.storage_offset(), a.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "63817087-0f50-4545-9b58-751edc4ba495",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.view(3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbee4e2-38de-4294-9c8c-632e78d6a57d",
   "metadata": {},
   "source": [
    "My guess is that it might create a tensor of size `[3, 3]`, which would look like this:\n",
    "```py\n",
    "[[0, 1, 2],\n",
    " [3, 4, 5],\n",
    " [6, 7, 8]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab280c6f-f119-4471-baff-d3743c9ce081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2],\n",
       "         [3, 4, 5],\n",
       "         [6, 7, 8]]),\n",
       " True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b, a.untyped_storage() == b.untyped_storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab700ce1-52d1-4bb7-89bc-41542fe8be73",
   "metadata": {},
   "source": [
    "I was correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1da0c532-a22b-43cc-aa97-f51a35f87a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = b[1:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446eb232-88af-4f5d-a3c1-9b821ac0065f",
   "metadata": {},
   "source": [
    "The size should be `[2, 2]`, the offset `3`$^1$, and the stride `(3, 1)`. If I'm correct, the tensor should look like this:\n",
    "```py\n",
    "[[4, 5],\n",
    " [7, 8]]\n",
    "```\n",
    "$^1$Ah, off-by-one. My beloved!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7521ff24-0e02-4564-95ce-1015c56c4a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4, 5],\n",
       "         [7, 8]]),\n",
       " torch.Size([2, 2]),\n",
       " 4,\n",
       " (3, 1))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c, c.size(), c.storage_offset(), c.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7811402-16e2-4192-b770-d04157273096",
   "metadata": {},
   "source": [
    "2. Pick a mathematical operation like cosine or square root. Can you find a corresponding function in the `torch` library?\n",
    "    1. Apply the function element-wise to `a`. Why does it return an error?\n",
    "    1. What operation is required to make the function work?\n",
    "    1. Is there a version of your function that operates in place?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e812d7-7ece-44da-9de9-d639f25eab8e",
   "metadata": {},
   "source": [
    "I'll pick atan. [Here](https://pytorch.org/docs/stable/generated/torch.atan.html) we go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f382798e-9ddf-40f6-a3f1-847455954003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result type Float can't be cast to the desired output type Long\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    a.atan_()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a9c670-2039-43d7-ba3a-af0fb23a7ec0",
   "metadata": {},
   "source": [
    "The error is telling us exactly what's needed, so let us cast the type with `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21e6ce61-1cd8-4dc3-ba52-c533e950ef6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.7854, 1.1071, 1.2490, 1.3258, 1.3734, 1.4056, 1.4289, 1.4464])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a.float()\n",
    "a.atan_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f84844-9ee8-47aa-a8b1-9521f4111641",
   "metadata": {},
   "source": [
    "I used the in-place version above, to produce the error. I'm assuming that, when the exercise was written, functions like `torch.atan` or `a.atan` would have caused an error, but now, only the in-place version does. Also, yes. There is a version of this function that operates in place. See above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
