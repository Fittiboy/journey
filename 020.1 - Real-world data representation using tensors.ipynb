{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fca4ceeb-3116-4e63-ae33-d208c994ccf6",
   "metadata": {},
   "source": [
    "# Day 20 - Real-world data representation using tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae588c1-2d8e-490b-9bd3-db5956af32e3",
   "metadata": {},
   "source": [
    "## Representing tabular data\n",
    "\n",
    "* Tabular data, in spreadsheets, is often heterogeneous\n",
    "* PyTorch tensors have to be homoegeneous, so this data has to be turned into floats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c5673a-b9f3-42da-b950-3ae42ba4e0e7",
   "metadata": {},
   "source": [
    "### Using a real-world dataset\n",
    "\n",
    "* A lot of datasets are freely available on the internet, like this [wine quality dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv)\n",
    "    * This dataset has 12 columns, where the first 11 are measures characteristics, and the final column a quality rating from 0 to 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1267643-4bba-4273-bd63-b5cdbcb14184",
   "metadata": {},
   "source": [
    "### Loading a wine data tensor\n",
    "\n",
    "* We first have to examine the data ourselves\n",
    "* Options for this include:\n",
    "    1. Python's `csv` module\n",
    "    2. NumPy\n",
    "    3. Pandas\n",
    "* Pandas wins\n",
    "* To avoid introducing yet another library, we will use NumPy for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68628bab-4f2e-4b6d-884e-a1c7549cafe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],\n",
       "       [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],\n",
       "       [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],\n",
       "       ...,\n",
       "       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n",
       "       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n",
       "       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]], dtype=float32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "wine_path = \"./DLPT/data/winequality-white.csv\"\n",
    "wineq_numpy = np.loadtxt(wine_path, dtype=np.float32, delimiter=\";\", skiprows=1)\n",
    "wineq_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1364ec33-2701-4500-8b1f-10942af22704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4898, 12),\n",
       " ['fixed acidity',\n",
       "  'volatile acidity',\n",
       "  'citric acid',\n",
       "  'residual sugar',\n",
       "  'chlorides',\n",
       "  'free sulfur dioxide',\n",
       "  'total sulfur dioxide',\n",
       "  'density',\n",
       "  'pH',\n",
       "  'sulphates',\n",
       "  'alcohol',\n",
       "  'quality'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = next(csv.reader(open(wine_path), delimiter=\";\"))\n",
    "\n",
    "wineq_numpy.shape, col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adc9714a-fc89-412d-bd14-7b84e99b4ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898, 12]), torch.float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "wineq = torch.from_numpy(wineq_numpy)\n",
    "\n",
    "wineq.shape, wineq.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56897a9-d25a-4811-ae68-82bfb2bc0930",
   "metadata": {},
   "source": [
    "### Representing scores\n",
    "\n",
    "* For training, we remove the label from the data, into a separate tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ea0b54b-6993-4d8f-b1a0-748c5e4b2080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7.0000,  0.2700,  0.3600,  ...,  3.0000,  0.4500,  8.8000],\n",
       "         [ 6.3000,  0.3000,  0.3400,  ...,  3.3000,  0.4900,  9.5000],\n",
       "         [ 8.1000,  0.2800,  0.4000,  ...,  3.2600,  0.4400, 10.1000],\n",
       "         ...,\n",
       "         [ 6.5000,  0.2400,  0.1900,  ...,  2.9900,  0.4600,  9.4000],\n",
       "         [ 5.5000,  0.2900,  0.3000,  ...,  3.3400,  0.3800, 12.8000],\n",
       "         [ 6.0000,  0.2100,  0.3800,  ...,  3.2600,  0.3200, 11.8000]]),\n",
       " torch.Size([4898, 11]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = wineq[:, :-1]\n",
    "data, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "257ee4f1-bb59-4d6a-8edd-3d5a92a0afc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6., 6., 6.,  ..., 6., 7., 6.]), torch.Size([4898]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = wineq[:, -1]\n",
    "target, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faca7cf9-eae5-4fa6-a243-13224fbede84",
   "metadata": {},
   "source": [
    "* We have two options for transforming the target into labels\n",
    "* The first one is to simply treat the labels as a vector of integer scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "037de2db-bd04-4a82-b075-5379f999d615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 6, 6,  ..., 6, 7, 6])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = wineq[:, -1].long()\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53d3b10-0175-4bb2-ac75-eecf1644d181",
   "metadata": {},
   "source": [
    "### One-hot encoding\n",
    "\n",
    "* The other approach is to perform one-hot encoding, where each target label becomes its own vector with one element for each possible value\n",
    "* All values will be zero, except the one corresponding to the target category\n",
    "* The first options induces ordering in the values, as well as a measure of distance between two scores\n",
    "* One-hot encoding is better suited when this is not the case, for example when assigning categories\n",
    "* PyTorch gives us the `scatter_` method for turning our target into the corresponding one-hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15c51913-05f6-4a89-98d6-9dad06c3d911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_onehot = torch.zeros(target.shape[0], 10)\n",
    "\n",
    "#                      dim,               index, src\n",
    "# Copies values from scr into dim, according to the indices in index\n",
    "target_onehot.scatter_(1  , target.unsqueeze(1), 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b08f7f8-f2de-4f16-99e3-b7efe54eb2b7",
   "metadata": {},
   "source": [
    "* As the second argument is required to have the same dimensionality as the tensor we `scatter_` into, we have to `unsqueeze` it to match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b3f9bd1-5c37-4771-9710-4bedec699192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[6],\n",
       "         [6],\n",
       "         [6],\n",
       "         ...,\n",
       "         [6],\n",
       "         [7],\n",
       "         [6]]),\n",
       " torch.Size([4898, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_unsqueezed = target.unsqueeze(1)\n",
    "target_unsqueezed, target_unsqueezed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1261827-6c5f-4a24-81ff-e31a152782d4",
   "metadata": {},
   "source": [
    "* PyTorch actually allows us to use class indices like `target` directly as targets during neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37720e0-913a-4a82-a109-50afa7737909",
   "metadata": {},
   "source": [
    "### When to categorize\n",
    "\n",
    "* When the data is continuous, or ordinal and ordering is a priority, use the values directly\n",
    "    * Remember that this introduces a notion of distance between the values\n",
    "* When the data is categorical, or ordering does not matter, use a one-hot encoding, or an embedding\n",
    "* Now to further manipulate our `data`, by calculating the mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1a49277-2005-4e39-89b6-d270c022bd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.8548e+00, 2.7824e-01, 3.3419e-01, 6.3914e+00, 4.5772e-02, 3.5308e+01,\n",
       "        1.3836e+02, 9.9403e-01, 3.1883e+00, 4.8985e-01, 1.0514e+01])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mean = torch.mean(data, dim=0)\n",
    "data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d220c858-642f-47e3-a037-f065340f0180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.1211e-01, 1.0160e-02, 1.4646e-02, 2.5726e+01, 4.7733e-04, 2.8924e+02,\n",
       "        1.8061e+03, 8.9455e-06, 2.2801e-02, 1.3025e-02, 1.5144e+00])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_var = torch.var(data, dim=0)\n",
    "data_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cc460a-46d7-4615-9981-4131f9e36da9",
   "metadata": {},
   "source": [
    "* Finally, we use these values to normalize the data, helping training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c5651c2-5c9c-467c-be72-d2a997107cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7208e-01, -8.1761e-02,  2.1326e-01,  ..., -1.2468e+00,\n",
       "         -3.4915e-01, -1.3930e+00],\n",
       "        [-6.5743e-01,  2.1587e-01,  4.7996e-02,  ...,  7.3995e-01,\n",
       "          1.3422e-03, -8.2419e-01],\n",
       "        [ 1.4756e+00,  1.7450e-02,  5.4378e-01,  ...,  4.7505e-01,\n",
       "         -4.3677e-01, -3.3663e-01],\n",
       "        ...,\n",
       "        [-4.2043e-01, -3.7940e-01, -1.1915e+00,  ..., -1.3130e+00,\n",
       "         -2.6153e-01, -9.0545e-01],\n",
       "        [-1.6054e+00,  1.1666e-01, -2.8253e-01,  ...,  1.0049e+00,\n",
       "         -9.6251e-01,  1.8574e+00],\n",
       "        [-1.0129e+00, -6.7703e-01,  3.7852e-01,  ...,  4.7505e-01,\n",
       "         -1.4882e+00,  1.0448e+00]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normalized = (data - data_mean) / torch.sqrt(data_var)\n",
    "data_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bd98ff-c76a-4b31-a35e-12793e094422",
   "metadata": {},
   "source": [
    "### Finding thresholds\n",
    "\n",
    "* To get a feel for the data, and help judge our model, we can look at the data ourselves to find easy ways of telling good and bad wines apart at a glance\n",
    "* Let us see if we can determine what makes a wine score 3 or lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "211aee7f-eb2e-4951-89a2-e08f91a4c52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(20))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_indexes = target <= 3\n",
    "bad_indexes.shape, bad_indexes.dtype, bad_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69b01870-1f9a-4276-a0ad-bd16da21fb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 11])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_data = data[bad_indexes]\n",
    "bad_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d590e6e-b05b-494e-a217-f9ebc145afdc",
   "metadata": {},
   "source": [
    "* We can now have a look at the average values for bad, mediocore, and good wines, to get a feel for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e954659b-97d8-4ffa-8ed9-628830cba29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 fixed acidity          0.88   0.04  -0.15\n",
      " 1 volatile acidity       0.55   0.03  -0.13\n",
      " 2 citric acid            0.01   0.02  -0.07\n",
      " 3 residual sugar         0.00   0.06  -0.22\n",
      " 4 chlorides              0.39   0.09  -0.35\n",
      " 5 free sulfur dioxide    1.06   0.01  -0.04\n",
      " 6 total sulfur dioxide   0.76   0.08  -0.31\n",
      " 7 density                0.29   0.15  -0.54\n",
      " 8 pH                    -0.01  -0.05   0.18\n",
      " 9 sulphates             -0.13  -0.02   0.09\n",
      "10 alcohol               -0.14  -0.20   0.73\n"
     ]
    }
   ],
   "source": [
    "bad_data = data_normalized[target <= 3]\n",
    "mid_data = data_normalized[(target > 3) & (target < 7)]\n",
    "good_data = data_normalized[target >= 7]\n",
    "\n",
    "bad_mean = torch.mean(bad_data, 0)\n",
    "mid_mean = torch.mean(mid_data, 0)\n",
    "good_mean = torch.mean(good_data, 0)\n",
    "\n",
    "for i, args in enumerate(zip(col_list, bad_mean, mid_mean, good_mean)):\n",
    "    print(\"{:2} {:20} {:6.2f} {:6.2f} {:6.2f}\".format(i, *args))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6003f4c-685a-44c5-804d-40a9478072dd",
   "metadata": {},
   "source": [
    "* We can see that the bad wines have a much higher sulfur dioxide content, among other differences\n",
    "* One crude criterion for discriminating good from bad wines would then be a threshold on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d84f58f-6cf6-46f1-8caa-aeb2fae3973b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(2727))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sulfur_threshold = data[(target > 3) & (target < 7)].mean(0)[6] # 141.83\n",
    "total_sulfur_data = data[:, 6]\n",
    "predicted_indexes = torch.lt(total_sulfur_data, total_sulfur_threshold)\n",
    "\n",
    "predicted_indexes.shape, predicted_indexes.dtype, predicted_indexes.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4977c78a-c72a-46a8-a5ea-76703c744fc8",
   "metadata": {},
   "source": [
    "* Using this threshold, about half of our wines would be considered high quality\n",
    "* We can compare this to the true indexes of the higher quality wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3f6effa-265c-4c59-9a44-1a7e1ae55609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(3258))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_indexes = target > 5\n",
    "\n",
    "actual_indexes.shape, actual_indexes.dtype, actual_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2aa9fd5-d2dc-4aed-9681-04b17466dcd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2018, 0.74000733406674, 0.6193984039287906)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_matches = torch.sum(actual_indexes & predicted_indexes).item()\n",
    "n_predicted = torch.sum(predicted_indexes).item()\n",
    "n_actual = torch.sum(actual_indexes).item()\n",
    "\n",
    "n_matches, n_matches / n_predicted, n_matches / n_actual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f59ec9-94e2-494e-b00e-9f582b41eea2",
   "metadata": {},
   "source": [
    "* 2018 of our predictions match with the actual data, which represents 74% of our predictions\n",
    "* About 62% of the actually good wines were included with this threshold\n",
    "* This is barely better than random, but can serve as a baseline for debugging model performance later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ec2eba-ad23-4b40-acbe-9fa0835db3ab",
   "metadata": {},
   "source": [
    "## Working with time series\n",
    "\n",
    "* The dataset we will be using the [bike sharing dataset](https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d9748b-f72a-4c8f-b979-b96328c642ba",
   "metadata": {},
   "source": [
    "### Adding a time dimension\n",
    "\n",
    "* In the original dataset, each row represents one hour\n",
    "* We want to reshape this data, so that we have one dimension along which the next index represents the next day\n",
    "* The next axis is then the hours of each day, with the third axis being the different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dafe40a0-1a17-4dd0-9294-8a342a16875d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 3.0000e+00, 1.3000e+01,\n",
       "         1.6000e+01],\n",
       "        [2.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 8.0000e+00, 3.2000e+01,\n",
       "         4.0000e+01],\n",
       "        [3.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 5.0000e+00, 2.7000e+01,\n",
       "         3.2000e+01],\n",
       "        ...,\n",
       "        [1.7377e+04, 3.1000e+01, 1.0000e+00,  ..., 7.0000e+00, 8.3000e+01,\n",
       "         9.0000e+01],\n",
       "        [1.7378e+04, 3.1000e+01, 1.0000e+00,  ..., 1.3000e+01, 4.8000e+01,\n",
       "         6.1000e+01],\n",
       "        [1.7379e+04, 3.1000e+01, 1.0000e+00,  ..., 1.2000e+01, 3.7000e+01,\n",
       "         4.9000e+01]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes_numpy = np.loadtxt(\n",
    "    \"./DLPT/data/bike-sharing-dataset/hour-fixed.csv\",\n",
    "    dtype=np.float32,\n",
    "    delimiter=\",\",\n",
    "    skiprows=1,\n",
    "    converters={1: lambda x: float(x[8:10])}\n",
    ")\n",
    "bikes = torch.from_numpy(bikes_numpy)\n",
    "\n",
    "bikes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e41f64-c9bd-46a3-91e7-29b494ad8425",
   "metadata": {},
   "source": [
    "* In a time series dataset, rows represent successive time-points\n",
    "* The existence of this ordering gives us the opportunity to exploit causal relationships"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
