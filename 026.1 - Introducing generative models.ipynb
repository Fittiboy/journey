{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46f6f51b-6c9a-40b8-9958-03ae812c3131",
   "metadata": {},
   "source": [
    "# Day 26 - Introducing generative models\n",
    "\n",
    "#### This chapter covers\n",
    "\n",
    "* An explanation of the text generation problem.\n",
    "* An introduction to unsupervised learning.\n",
    "* Learning structure using attention mechanism.\n",
    "* Building up from simple probabilistic models to deep learning models.\n",
    "* The transformer architecture and its variants and applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6f8b91-7368-438d-878a-d7c0a30c73b5",
   "metadata": {},
   "source": [
    "## A motivating example: generating names character by character\n",
    "\n",
    "* We need to be able to map between characters and integers\n",
    "* We shall use the special character $\\$$ to denote the beginning and the end of a name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "add93878-ed85-469f-b134-f8780638d434",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = \"$abcdefghijklmnopqrstuvwxyz\"\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "ch_to_i = {ch: i for i, ch in enumerate(vocab)}\n",
    "i_to_ch = {i: ch for i, ch in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36df8a82-e17b-44ea-b629-d8ece8115d2c",
   "metadata": {},
   "source": [
    "* A crude first step is uniform random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38b75cfe-35fd-48cd-acac-923a4a8ea44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name 1: zpuevmmykoejo\n",
      "Name 2: jrrttmmywahjrqunqsmzklhixawlsobgbmzbcvcdc\n",
      "Name 3: nxpsackyde\n",
      "Name 4: vcujbckryarjmvbcoangkghyrxgijizoiuvjimeffjnqhgodvkkqjgmcfnkuuytienkvvuxprfaxevfzz\n",
      "Name 5: pzjdwynriegdgwmhurloyjwehafhcinojtiotq\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "uniform_probs = F.softmax(torch.ones(vocab_size), dim=0)\n",
    "for i in range(5):\n",
    "    generated = \"\"\n",
    "    while True:\n",
    "        random_int = torch.multinomial(uniform_probs, 1).item()\n",
    "        if random_int == 0:\n",
    "            break\n",
    "        generated += i_to_ch[random_int]\n",
    "    print(f\"Name {i+1}:\", generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cef072-7f10-4001-9d21-e0228debcef2",
   "metadata": {},
   "source": [
    "* These names are no particularly good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cfbd53-44e1-43cd-888d-0d2139dca68f",
   "metadata": {},
   "source": [
    "## Self-supervised learning\n",
    "\n",
    "* We steal the [names of American children](https://www.ssa.gov/oact/babynames/names.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bddc383-ceb6-48f2-bfb1-821b443dcf89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31682,\n",
       " ['$olivia$', '$emma$', '$charlotte$'],\n",
       " ['$zymirr$', '$zyquan$', '$zyrin$'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = []\n",
    "with open('./DLPT/data/text/names/yob2023.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        name, _, _= line.lower().strip().split(',')\n",
    "        names.append(\"$\" + name + \"$\")\n",
    "len(names), names[:3], names[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0d79f8-9a9e-4e3b-98b8-685eaccf7a92",
   "metadata": {},
   "source": [
    "* We can now calculate the frequencies of all bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b558e09c-3b4e-4982-9f2a-99e20fcb99c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = torch.zeros((vocab_size, vocab_size))\n",
    "total = 0\n",
    "for name in names:\n",
    "    for ch1, ch2 in zip(name, name[1:]):\n",
    "        ch1_idx = ch_to_i[ch1]\n",
    "        ch2_idx = ch_to_i[ch2]\n",
    "        bigram[ch1_idx][ch2_idx] += 1\n",
    "        total += 1\n",
    "bigram /= total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee65b5b-5d52-4401-b1cd-d461c9eb2f25",
   "metadata": {},
   "source": [
    "* And then, we can sample according to these, instead of the uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6426f0e2-e80d-4fe3-83c5-7b9220afa295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 0: josondr\n",
      "name 1: zirio\n",
      "name 2: cendeonsuglunahlessemiam\n",
      "name 3: kh\n",
      "name 4: m\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    generated = \"$\"\n",
    "    while True:\n",
    "        bigram_probs = bigram[ch_to_i[generated[-1]]]\n",
    "        sampled_char = i_to_ch[\n",
    "            torch.multinomial(bigram_probs, 1).item()\n",
    "        ]\n",
    "        if sampled_char == \"$\":\n",
    "            break\n",
    "        generated += sampled_char\n",
    "    print(f\"name {i}: {generated[1:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52228dfa-83c3-46e1-a973-ac0e96bf0be3",
   "metadata": {},
   "source": [
    "* These are names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fe9052-8ddf-4572-aef0-1c8ec88eb46d",
   "metadata": {},
   "source": [
    "## Generating our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5a4d95d-8f6c-4bc2-b2b6-ab0a27e31d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 4, 1, 0])\n",
      "$ada$\n"
     ]
    }
   ],
   "source": [
    "example_name = \"$ada$\"\n",
    "# Define encode and decode functions\n",
    "encode = lambda word: torch.tensor([ch_to_i[c] for c in word])\n",
    "decode = lambda tensor_i: ''.join(i_to_ch[i.item()] for i in tensor_i)\n",
    "print(encode(example_name))\n",
    "print(decode(encode(example_name)))\n",
    "\n",
    "name_indices = [encode(name) for name in names]\n",
    "target_indices = [name_index[1:] for name_index in name_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dbb7405-274b-43bc-b7f9-72e4d2052efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 15, 12,  9, 22,  9,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "tensor([15, 12,  9, 22,  9,  1,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "X = pad_sequence(name_indices, batch_first=True, padding_value=0)\n",
    "max_name_length = max(len(name) for name in names)\n",
    "target_indices.append(torch.empty((max_name_length), dtype=torch.long))\n",
    "Y = pad_sequence(target_indices, batch_first=True, padding_value=-1)[:-1]\n",
    "print(X[0])\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6acb1d6a-3bc8-41c8-b3d9-91e2b6220063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size=64):\n",
    "    random_idx = torch.randint(0, X.size(0), (batch_size,))\n",
    "    inputs = X[random_idx]\n",
    "    labels = Y[random_idx]\n",
    "    return inputs.to(device=device, non_blocking=True), labels.to(device=device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "037bab9e-1ad2-4c96-a60c-669daff7228f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  3,  8,  1, 18, 22,  9, 11,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 0,  5, 13, 13,  1, 12, 25, 14, 14,  5,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 0, 13,  9, 14,  4,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 3,  8,  1, 18, 22,  9, 11,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
      "        [ 5, 13, 13,  1, 12, 25, 14, 14,  5,  0, -1, -1, -1, -1, -1, -1, -1],\n",
      "        [13,  9, 14,  4,  1,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "inputs, labels = get_batch(3)\n",
    "print(inputs)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf65717e-4402-429a-a4d9-dd07f607f04e",
   "metadata": {},
   "source": [
    "## Embeddings and multi-layer perceptrons\n",
    "\n",
    "* PyTorch provides the `Embedding` module, which simplifies the embedding process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "252c8bcb-e337-4968-9e3a-c36fe3fb372a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3064,  1.4244,  1.4227],\n",
       "        [ 1.3064,  1.4244,  1.4227],\n",
       "        [ 0.3055, -0.7097, -0.9754],\n",
       "        [ 0.4251, -0.0573,  0.6399]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 3\n",
    "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "example_input = torch.tensor([1, 1, 0, 2])\n",
    "input_embd = embedding(example_input)\n",
    "print(input_embd.shape)\n",
    "input_embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6656ef9d-85e8-4c16-84df-4afd5cc0bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceMLP(nn.Module):\n",
    "    def __init__(self, vocab_size, max_sequence_length,\n",
    "     embedding_dim, hidden_dim=32):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear = nn.Linear(embedding_dim * max_sequence_length,\n",
    "         hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = self.linear.weight.device\n",
    "        batch_size, seq_len = x.shape\n",
    "        sequence_embeddings = torch.zeros(batch_size, seq_len,\n",
    "         self.max_sequence_length * self.embedding_dim, device=device)\n",
    "        for i in range(seq_len):\n",
    "            subsequence = torch.zeros(batch_size, self.max_sequence_length,\n",
    "             dtype=torch.int, device=device)\n",
    "            prefix = x[:, :i+1]\n",
    "            subsequence[:, :i+1] = prefix\n",
    "            emb = self.embedding(subsequence)\n",
    "            sequence_embeddings[:, i, :] = emb.view(batch_size, -1)\n",
    "        x = self.linear(sequence_embeddings)\n",
    "        x = self.relu(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91311030-d0d6-43d2-ba47-ccc25dde3d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 3\n",
    "max_sequence_length = X.shape[1]\n",
    "model = SequenceMLP(vocab_size, max_sequence_length, embedding_dim).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "654ae67a-68e2-4415-b1c4-cc2dff187d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def train(model, optimizer, num_steps=10_001, loss_report_interval=1_000):\n",
    "    losses = []\n",
    "    for i in tqdm(range(1, num_steps), desc=\"Epochs\"):\n",
    "        inputs, labels = get_batch()\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(inputs)\n",
    "        loss = F.cross_entropy(logits.view(-1, logits.shape[-1]),\n",
    "                               labels.view(-1), ignore_index=-1)\n",
    "        losses.append(loss.item())\n",
    "        if i % loss_report_interval == 0:\n",
    "            print(f'Average loss at step {i}: {\n",
    "            sum(losses[-loss_report_interval:]) / loss_report_interval:.4f\n",
    "            }')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a51d63ca-7e07-40ae-8edb-3776f0cb7c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39e3651379c478a803c05a4250afc7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 10000: 2.3325\n",
      "Average loss at step 20000: 2.2936\n",
      "Average loss at step 30000: 2.2839\n",
      "Average loss at step 40000: 2.2821\n",
      "Average loss at step 50000: 2.2802\n",
      "Average loss at step 60000: 2.2779\n",
      "Average loss at step 70000: 2.2767\n",
      "Average loss at step 80000: 2.2739\n",
      "Average loss at step 90000: 2.2736\n",
      "Average loss at step 100000: 2.2729\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, num_steps=100_001, loss_report_interval=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1edca813-30e7-4d19-8e4e-f2845e256e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(model, num_samples=1, max_len=max_name_length):\n",
    "    sequences = torch.zeros((num_samples, 1)).int()\n",
    "    for _ in range(max_len):\n",
    "        logits = model(sequences)\n",
    "        logits = logits[:, -1, :]\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        sequences = torch.cat((sequences, idx_next), dim=1)\n",
    "\n",
    "    for sequence in sequences:\n",
    "        indices = torch.where(sequence == 0)[0]\n",
    "        end = indices[1] if len(indices) > 1 else max_len\n",
    "        sequence = sequence[1:end]\n",
    "        print(decode(sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9ed3494-d4a4-4c41-a378-35f1ad5edc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ruviah\n",
      "nadar\n",
      "zoriah\n",
      "errly\n",
      "assisteh\n",
      "maillen\n",
      "modyohah\n",
      "koviane\n",
      "luenza\n",
      "lenian\n"
     ]
    }
   ],
   "source": [
    "generate_samples(model.to(device=\"cpu\"), num_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0443344e-e649-423b-8675-7f6b8eaa0ddd",
   "metadata": {},
   "source": [
    "## Attention\n",
    "\n",
    "* Attention can be used as a mechanism to adjust the embedding of a token based on the surrounding context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a86f34-99b6-48dc-8fd1-a2db633d998e",
   "metadata": {},
   "source": [
    "### Dot Product Self-attention\n",
    "\n",
    "* A self-attention block, denoted $\\mathcal{sa[\\cdot]}$ takes $N$ inputs $x_1, x_2, \\dots, x_N$, each of dimension $D$\n",
    "* $Values$ are a simple, linear transformation of the inputs\n",
    "* They can thus be calculated by applying a `Linear(D, D)` layer to them\n",
    "* The $n$-th output of the self-attention block, $\\text{sa}_n[x_1, \\dots, x_N]$, is a weighted sum of the inpute values\n",
    "\n",
    "$$\n",
    "\\text{sa}_n\\left[x_1, \\dots, x_N\\right]=\\sum_{m=1}^{N}a\\left[x_m,x_n\\right]v_m\n",
    "$$\n",
    "* Here, $a[x_m, x_n]$ is a learned weight function\n",
    "* This means that self-attention transforms each token in a sequence into a weighted average of all tokens\n",
    "* To compute $a$, we generate a $query$ and a $key$ for each token, which are both simply `Linear(D, D)` transformations again\n",
    "* For $a[x_m, x_n]$, we take take the dot products of $q_n$ with all $k$, then get the softmax for $k_m$\n",
    "\n",
    "$$\n",
    "a[x_m, x_n]=\\operatorname{softmax}(q_n\\cdot k_m)=\\frac{q_n\\cdot k_m}{\\sum_{m'=1}^Nq_n\\cdot k_{m'}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5915e28b-8986-4fad-b983-be126012f2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.rand(2, 3)\n",
    "\n",
    "query = F.linear(x, weight=torch.rand(3, 3), bias=torch.rand(3))\n",
    "key = F.linear(x, weight=torch.rand(3, 3), bias=torch.rand(3))\n",
    "value = F.linear(x, weight=torch.rand(3, 3), bias=torch.rand(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0df9c65-c5b7-432f-87f1-3c41f2bd28c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product_attention_single(q, k, v):\n",
    "    attn_weights = q @ k.T\n",
    "    attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "    output = attn_weights @ v\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f9aa930-107b-42d4-8e91-ad1b62cac1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3667, 0.6913, 1.0614],\n",
       "        [1.3718, 0.6930, 1.0627]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product_attention_single(query, key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7587a6cb-6950-4f78-af45-439b424e0ce6",
   "metadata": {},
   "source": [
    "### Scaled dot product causal self-attention\n",
    "\n",
    "* We can extend this attention mechanism by handling batching, causal masking (hiding the future), and scaling the weights to avoid vanishing and exploding gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "965c402e-48f2-46fa-97c4-bc44e69dfd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.rand(1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aebb4849-be9a-41f9-9c36-13a08aaf2ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = F.linear(x, weight=torch.rand(3, 3), bias=torch.rand(3))\n",
    "key = F.linear(x, weight=torch.rand(3, 3), bias=torch.rand(3))\n",
    "value = F.linear(x, weight=torch.rand(3, 3), bias=torch.rand(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89ade9be-a87f-4af0-babe-debf0b2a7571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_causal_attention(q, k, v):\n",
    "    attn_weights = q @ k.transpose(1, 2)\n",
    "    mask = torch.tril(torch.ones(attn_weights.shape[1:]), diagonal=0)\n",
    "    attn_weights = attn_weights.masked_fill(mask == 0, value=float('-inf'))\n",
    "    attn_weights = attn_weights / torch.sqrt(torch.tensor(\n",
    "        k.shape[-1]).float())\n",
    "    attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "    output = attn_weights @ v\n",
    "    return output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1825954-0774-4e1e-826c-c17f7fd33fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.6253, 0.7788, 1.1252],\n",
       "         [1.3849, 0.6974, 1.0659]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, attn_weights = scaled_dot_product_causal_attention(query, key, value)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805e1cfb-1043-4e53-ac94-ca300a1fb17e",
   "metadata": {},
   "source": [
    "* Of course, there is a native PyTorch solution for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91e48775-a3d2-4d3a-bba4-e8223784b3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "expected_output = F.scaled_dot_product_attention(query, key, value, is_causal=True)\n",
    "print(torch.allclose(output, expected_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe31b68-eb4d-437a-8034-23bef5d25ea7",
   "metadata": {},
   "source": [
    "* Using this new attention mechanism, we can hopefully generate better names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60c053d6-b156-4747-a193-3b6128df8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionMLP(nn.Module):\n",
    "    def __init__(self, n_embd, vocab_size, block_size, n_hidden=64):\n",
    "        super().__init__()\n",
    "        self.tok_embd = nn.Embedding(vocab_size, n_embd)\n",
    "        self.attn_weights = None\n",
    "\n",
    "        self.query_proj = nn.Linear(n_embd, n_embd)\n",
    "        self.key_proj = nn.Linear(n_embd, n_embd)\n",
    "        self.value_proj = nn.Linear(n_embd, n_embd)\n",
    "\n",
    "        self.register_buffer(\"mask\", torch.tril(torch.ones(\n",
    "            (block_size, block_size), device=device), diagonal=0))\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(n_embd, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_embd)\n",
    "        )\n",
    "\n",
    "        self.output_proj = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = self.output_proj.weight.device\n",
    "        \n",
    "        x = self.tok_embd(x)\n",
    "        batch_size, seq_len, embd_dim = x.shape\n",
    "\n",
    "        q = self.query_proj(x)\n",
    "        k = self.key_proj(x)\n",
    "        v = self.value_proj(x)\n",
    "\n",
    "        attn_weights = q @ k.transpose(1, 2)\n",
    "        attn_weights = attn_weights.masked_fill(\n",
    "            self.mask[:seq_len, :seq_len] == 0, value=float('-inf'))\n",
    "        attn_weights = attn_weights / torch.sqrt(\n",
    "            torch.tensor(k.shape[-1], device=device).float())\n",
    "        self.attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "        x = self.attn_weights @ v\n",
    "        x = self.mlp(x)\n",
    "\n",
    "        x = self.output_proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93fedf4f-2702-4030-9703-698ddf61ecac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4899ffc99746451fa2bdddb0caa38e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 10000: 2.2593\n",
      "Average loss at step 20000: 2.2265\n",
      "Average loss at step 30000: 2.2205\n",
      "Average loss at step 40000: 2.2178\n",
      "Average loss at step 50000: 2.2173\n",
      "Average loss at step 60000: 2.2161\n",
      "Average loss at step 70000: 2.2145\n",
      "Average loss at step 80000: 2.2145\n",
      "Average loss at step 90000: 2.2139\n",
      "Average loss at step 100000: 2.2149\n"
     ]
    }
   ],
   "source": [
    "model = AttentionMLP(32, vocab_size, max_name_length).to(device=device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "train(model, optimizer, num_steps=100_001, loss_report_interval=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e1dc3e1-36e0-40c5-b81c-9e3b9f11790f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pema\n",
      "distran\n",
      "tarianta\n",
      "narayah\n",
      "analinalah\n",
      "jianah\n",
      "blacalyen\n",
      "ronen\n",
      "uuzre\n",
      "kairzo\n"
     ]
    }
   ],
   "source": [
    "generate_samples(model.to(device=\"cpu\"), 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
