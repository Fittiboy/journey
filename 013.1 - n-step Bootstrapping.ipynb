{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1751e35-ec8d-4dc0-874d-debd628c59b9",
   "metadata": {},
   "source": [
    "# Day 13 - $n$-step Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6a7397-7fb0-4800-a28a-9633041d6cc6",
   "metadata": {},
   "source": [
    "## Off-policy Learning Without Importance Sampling: The $n$-step Tree Backup Algorithm\n",
    "\n",
    "* Just like Expected Sarsa was able to eliminate importance sampling in the one-step case, this can be done in the $n$-step case\n",
    "* At each step of the return, the update can be the same as the one-step Expected Sarsa update, with one term of the expectation replaced by the actually experienced reward, plus the discounted next step, even allowing for a recursive definition:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "G_{t:t+n}&\\doteq R_{t+1}+\\gamma\\sum_{a\\ne A_{t+1}}\\pi(a|S_{t+1})Q_{t+n-1}(S_{t+1},a) \\\\\n",
    "&+\\gamma\\pi(A_{t+1}|S_{t+1})\\Biggl(R_{t+2}+\\gamma\\sum_{a\\ne A_{t+2}}\\pi(a|S_{t+2})Q_{t+n-1}(S_{t+2},a)+\\dots \\\\\n",
    "&+\\gamma^{n-1}\\pi(A_{t+n-1}|S_{t+n-1})\\Bigl(R_{t+n}+\\gamma\\sum_aQ_{t+n-1}(S_{t+n},a)\\Bigr)\\dots\\Biggr) \\\\\n",
    "&=R_{t+1}+\\gamma\\sum_{a\\ne A_{t+1}}\\pi(a|S_{t+1})Q_{t+n-1}(S_{t+1},a)+\\gamma\\pi(A_{t+1}|S_{t+1})G_{t+1:t+n}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "* The tail of the recursion is just the usual one-step Expected Sarsa update, making it a special case of this $n$-step Tree Backup algorithm:\n",
    "\n",
    "$$\n",
    "G_{t:t+1}\\doteq R_{t+1}+\\gamma\\sum_a\\pi(a|S_{t+1})Q_t(S_{t+1}, a)\n",
    "$$\n",
    "* For terminal steps:\n",
    "\n",
    "$$\n",
    "G_{T-1:t+n}\\doteq R_T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776d37f0-fda4-454a-8088-02fc7947f609",
   "metadata": {},
   "source": [
    "### $Exercise\\ \\mathcal{7.11}$\n",
    "\n",
    "#### Show that if the approximate action values are unchanging, then the tree-backup return (7.16) can be written as a sum of expectation-based TD errors: $$G_{t:t+n}=Q(S_t,A_t)+\\sum_{k=t}^{min(t+n,T)-1}\\delta_k\\prod_{i=t+1}^k\\gamma\\pi(A_i|S_i),$$ where $\\delta_t\\doteq R_{t+1}+\\gamma\\bar{V}_t(S_{t+1})-Q(S_t,A_t)$ and $\\bar{V}_t$ is given by (7.8).\n",
    "\n",
    "As always, we start by subtracting $Q(S_t,A_t)$ from both the return:\n",
    "$$\n",
    "\\begin{align}\n",
    "G_{t:t+n}-Q(S_t,A_t)&=R_{t+1}+\\gamma \\bar{V}(S_{t+1})-Q(S_t,A_t)+\\gamma\\sum_{a\\ne A_{t+1}}\\pi(a|S_{t+1})Q(S_{t+1},a)+\\gamma\\pi(A_{t+1}|S_{t+1})G_{t+1:t+n}-\\gamma \\bar{V}(S_{t+1}) \\\\\n",
    "&=\\delta_t+\\gamma\\Bigl(\\sum_{a\\ne A_{t+1}}\\pi(a|S_{t+1})Q(S_{t+1},a)-\\sum_a\\pi(a|S_{t+1})Q(S_{t+1},a)+\\pi(A_{t+1}|S_{t+1})G_{t+1:t+n}\\Bigr) \\\\\n",
    "&=\\delta_t+\\gamma\\pi(A_{t+1}|S_{t+1})\\Bigl(G_{t+1:t+n}-Q(S_{t+1},A_{t+1})\\Bigr) \\\\\n",
    "&=\\delta_t+\\gamma\\pi(A_{t+1}|S_{t+1})\\biggl(\\delta_{t+1}+\\gamma\\pi(A_{t+2}|S_{t+2})\\Bigl(G_{t+2:t+n}-Q(S_{t+2},A_{t+2})\\Bigr)\\biggr) \\\\\n",
    "&=\\sum_{k=t}^{min(T,t+n)-1}\\delta_k\\prod_{i=t+1}^k\\gamma\\pi(A_{i}|S_{i})\n",
    "\\end{align}\n",
    "$$\n",
    "Adding back $Q(S_t,A_t)$ now gives us the desired equation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aad23b1-9c4b-40ac-8afd-1ad90e643606",
   "metadata": {},
   "source": [
    "## *A Unifying Algorithm: $n$-step $Q(\\sigma)$\n",
    "\n",
    "* This is a way to generalize across all the previous $n$-step methods\n",
    "* I may have a look at this at some point"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
