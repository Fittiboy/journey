{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6572d44c-1944-4a33-80a8-821f75b4c819",
   "metadata": {},
   "source": [
    "# Day 13 - Introducing deep learning and the PyTorch Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef99d249-ff17-420f-b0ed-c5cc56d8618c",
   "metadata": {},
   "source": [
    "## The deep learning revolution\n",
    "\n",
    "* Before the deep learning revolution, much of machine learning focused on $feature\\ engineering$\n",
    "* Deep learning enabled learned features to be used, instead of requiring practitioners to engineer them manually\n",
    "* Automatically learned features are often better than manually engineered ones\n",
    "* What is needed for deep learning:\n",
    "    * Ingesting data\n",
    "    * Define the deep learning machine\n",
    "    * Train the machine\n",
    "* The goal of training is to drive the $criterion$ (loss function) lower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ad9d0a-1f3e-4f12-b26c-5428afa30618",
   "metadata": {},
   "source": [
    "## PyTorch for deep learning\n",
    "\n",
    "* PyTorch is an excellent library for introducing deep learning, as it is clear, streamlined, popular, and easy to debug\n",
    "* The core data structure in PyTorch is the $tensor$, which is a multidimensional array similar to NumPy arrays\n",
    "* Along with these, PyTorch comes with tools to accelerate mathematical operations on dedicated hardware, like GPUs\n",
    "* The aim of the book is to cover enough ground to allow solving real-world problems and understanding new models as the pop up on arXiv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8a4e07-ffb8-4677-97e4-7c85e25d04d6",
   "metadata": {},
   "source": [
    "## Why PyTorch?\n",
    "\n",
    "* In order to practically solve problems, we need tools that are flexible, efficient, and perform with variability in the input data\n",
    "* PyTorch is simple and Pythonic\n",
    "* It provides two key features:\n",
    "    * Acceleration via GPU\n",
    "    * Numerical optimiztion for mathematical expressions\n",
    "* These extend beyond deep learning into high performance scientific computing in general\n",
    "* PyTorch is very expressive, avoiding undue complexity\n",
    "* It provides one of the most seamless transitions from idea to code, in deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb77496-8e2e-418a-8576-81af62f10d0f",
   "metadata": {},
   "source": [
    "### The deep learning competitive landscape\n",
    "\n",
    "* The release of PyTorch marked the beginning of a unification in the deep learning space, which was previously composed of many tools and libraries\n",
    "* In industry today, most technology is built using PyTorch, TensorFlow, or Hugging Face\n",
    "* Hugging Face is an application-oriented high level wrapper, allowing users to share pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402eeaf1-a851-4806-a4f8-5a51c35779dd",
   "metadata": {},
   "source": [
    "## An overview of how PyTorch supports deep learning projects\n",
    "\n",
    "* PyTorch provides tensors and ways to operate on them, on the CPU or the GPU\n",
    "* Moving from CPU to GPU, or back, is usually extremely simple\n",
    "* Tensors remember operations done on them, used by autograd, the automatic differentiation engine\n",
    "* The typical workflow is to load data, train a model, and then deploy the model\n",
    "* The building blocks for neural networks, including layers, activation functions, and loss functions, reside in `torch.nn`\n",
    "* The bridge between our raw data, and PyTorch's tensors, is the `Dataset` class from `torch.utils.data`\n",
    "* Loading this data quickly during training is done with the `DataLoader` class\n",
    "* Training is usually done in a simple `for` loop\n",
    "* In the loop, the model is evaluated on a batch of samples from the data loader\n",
    "* The model's output is compared to the desired output, using our $loss\\ function$ or $criterion$\n",
    "* Using autograd and an $optimizer$ from `torch.optim`, the model is then adjusted to produce the desired output\n",
    "* As it is becoming increasingly more common to use multiple GPUs, or even multiple machines, `torch.distributed` provides functionality for this\n",
    "* For the $trained$ model to be useful, it needs to be $deployed$\n",
    "* We can export the model by serializing it into $TorchScript$, or exporting it in the [$ONNX$](https://onnx.ai/) format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e20fff-2a90-4977-9840-dfcecdf75044",
   "metadata": {},
   "source": [
    "## Hardware and software requirements\n",
    "\n",
    "* Running a pretrained network is doable on a PC, or even a laptop\n",
    "* Training, however, takes a long time, due to the number of loops\n",
    "* For this, a CUDA-capable GPU brings at least an order of magnitude of speedup, usually 40-50x\n",
    "* Larger networks may take hours or days to train\n",
    "* This can be reduced by using a high-end GPU, using multiple GPUs, or even using multiple machines with multiple GPUs\n",
    "* The latter is less prohibitive than it sounds, due to cloud computing providers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4468cdc7-6a45-4a81-ac70-a5df02dfa854",
   "metadata": {},
   "source": [
    "### Using Jupyter Notebooks\n",
    "\n",
    "* This is a Jupyter notebook\n",
    "* I clearly don't need to take notes on this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278a5d4a-3b59-4d34-8d44-90dd3563dde7",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
