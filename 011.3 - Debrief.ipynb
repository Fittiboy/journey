{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8422259e-f4fd-4fe9-8efe-5213490e83a4",
   "metadata": {},
   "source": [
    "# Day 11 - Debrief"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8f3e30-9110-4ff2-bc94-86d0e1674185",
   "metadata": {},
   "source": [
    "## What I did today\n",
    "\n",
    "Today, I finished the sixth chapter of Sutton & Barto, and started on the seventh. I also ran some more experiments, and ended the day by implementing $n$-step Expected Sarsa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd77dd1-39ae-4449-85b7-aa5942ffa0d2",
   "metadata": {},
   "source": [
    "## What I learned today\n",
    "\n",
    "Finishing chapter 6, I learned about maximization bias and double learning, where two separate estimates are kept, to avoid that bias. The maximization bias comes from the fact that under stochasticity, nonoptimal values are easily overestimated early on, which can be slow to fix.\n",
    "\n",
    "Next, I learned about the concept of afterstates, where values are not estimated for states or state-action pairs, but for the states that are known to follow our chosen action. This is advantageous if we know the one-step dynamics of the environment, like in a game, as multiple state-action pairs can lead to the same afterstate. Updating the value estimate of that afterstate then implicitly updates the values of all state-action pairs that lead there. Aside from this specific special case, many different problems have opportunities for practical improvements like these.\n",
    "\n",
    "Afterwards, in the seventh chatper, I was introduced to $n$-step TD methods for prediction and for on-policy control. With $n$-step methods, we generalize from MC and TD methods, which are extreme cases of $n$-step methods, where the truncated return $G_{t:t+n}=\\sum_{k=t}^{t+n-1}\\gamma^{k-t}R_{k+1}+\\gamma^nV(S_{t+n})$ is used in the update. The on-policy $n$-step control methods I was introduced to were the $n$-step variants of Sarsa and Expected Sarsa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21abfce1-eec0-4805-94f7-978069704b1e",
   "metadata": {},
   "source": [
    "## Notes and questions for the next day\n",
    "\n",
    "I'm happy with how much programming I do now. Next up, I want to make sure I make it a habit to visualize results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
