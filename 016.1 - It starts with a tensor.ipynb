{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a7ea33c-c8c9-40a5-8db4-790399471170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a835cfc7-e36a-44d5-b056-c931077bf3a7",
   "metadata": {},
   "source": [
    "# Day 16 - It starts with a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcd92ea-effd-4bbd-87b9-3cdff045711d",
   "metadata": {},
   "source": [
    "## Tensors: Multidimensional arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1d37e0-4dcd-4174-8f40-eee03bd9627c",
   "metadata": {},
   "source": [
    "### From Python lists to PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b16fab35-ab85-4c44-afff-98bed09dd840",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1.0, 2.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2058e5c0-1e60-49ad-bb73-54a85a95eb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a25b5ca-7a35-4907-8da7-dc19d2ff8390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 2.0, 3.0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2] = 3.0\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5370adb3-f175-425c-840e-7f06e9222844",
   "metadata": {},
   "source": [
    "### Constructing our first tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a5facac-0536-4551-a322-22bd037608b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.ones(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "420181ba-ad97-478b-9cc0-199a5f61dd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f350973a-a6a8-4548-87db-ece887980d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71c5719c-bb85-44ac-ba23-97e392788a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 2.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2] = 2.0\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1c00b6-e912-405a-85c1-ef2ea71a4a3d",
   "metadata": {},
   "source": [
    "### The essence of tensors\n",
    "\n",
    "* Python lists and tuples of numbers are stored as individual objects in memory\n",
    "* A PyTorch tensors (and NumPy nparrays) are views over (typically) contiguous memory blocks\n",
    "* A 1D tensor of 1,000,000 32-bit floats will take up 4,000,000 contiguous bytes (+ metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2afbb909-8442-42d0-a066-e08105d6d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A triangle, with x and y coordinates of each point stored alternatingly\n",
    "# (4, 1), (5, 3), (2, 1)\n",
    "points = torch.zeros(6)\n",
    "points[0] = 4.0\n",
    "points[1] = 1.0\n",
    "points[2] = 5.0\n",
    "points[3] = 3.0\n",
    "points[4] = 2.0\n",
    "points[5] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41acb652-c016-4b52-a750-56dc18e51b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1., 5., 3., 2., 1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternate expression\n",
    "points = torch.tensor([4.0, 1.0, 5.0, 3.0, 2.0, 1.0])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05a9255c-7b18-466e-a447-cc848a49497e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0, 1.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First point\n",
    "float(points[0]), float(points[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7b0bf7-7e74-4de5-b96b-d85b2edc3c67",
   "metadata": {},
   "source": [
    "* It would be much more practical to store these as actual pairs\n",
    "* We can do so with a 2D tensor\n",
    "* The first index refers to points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a889bd40-a26b-4807-8959-f7b963b4bb49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b2211ee-1704-4ce1-90da-dc2327e7458e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36e592c-1881-4d18-b194-626d7cf0bc0e",
   "metadata": {},
   "source": [
    "* We can also pass a size as arguments to the `torch.zeros` constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6402d059-ba58-4aae-8296-135a84b07875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.zeros(3, 2)\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e02c5f9-7f95-4f85-a634-e7d4aeb51fe9",
   "metadata": {},
   "source": [
    "* The second index refers to individual coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c6361b7-f92b-42ac-b9bf-310e4ec40215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d04a3d10-43ab-499b-89de-f798109ea0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a188eacf-a67c-4485-afcf-22b791227fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7dcc7b-2a84-46c2-bf5a-2012778db8cb",
   "metadata": {},
   "source": [
    "* The outputs that we are seeing here are just different views over the same contiguous data\n",
    "* They are separate tensors, but view the same underlying memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88199526-224c-4442-9925-ca9ab3535307",
   "metadata": {},
   "source": [
    "## Indexing tensors\n",
    "\n",
    "* Just like Python lists can be indexed with ranges, so can PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "059e798f-9188-4a99-acdf-6d0db23e64e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5]\n",
      "[1, 2, 3]\n",
      "[1, 2, 3, 4, 5]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1, 2, 3, 4]\n",
      "[1, 3]\n"
     ]
    }
   ],
   "source": [
    "some_list = list(range(6))\n",
    "print(some_list[:])\n",
    "print(some_list[1:4])\n",
    "print(some_list[1:])\n",
    "print(some_list[:4])\n",
    "print(some_list[:-1])\n",
    "print(some_list[1:4:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daa15b9-e846-44ed-9c29-3c14ce3d390c",
   "metadata": {},
   "source": [
    "* PyTorch tensors have the advantage that they can be indexed by multiple, comma-separated ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2fe8099-7659-4623-9109-c0f763a186c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 3.],\n",
      "        [2., 1.]])\n",
      "tensor([[5., 3.],\n",
      "        [2., 1.]])\n",
      "tensor([5., 2.])\n",
      "tensor([[[4., 1.],\n",
      "         [5., 3.],\n",
      "         [2., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "print(points[1:])\n",
    "print(points[1:, :])\n",
    "print(points[1:, 0])\n",
    "print(points[None])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934a4c4e-5e51-4662-918d-2493448b9bd1",
   "metadata": {},
   "source": [
    "* PyTorch also allows for $advanced\\ indexing$, which we will have a look at later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5861685b-29c9-4097-8a8d-97eb987d702d",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "\n",
    "* PyTorch support's NumPy's broadcasting semantics\n",
    "* Dimensions are compared right-to-left\n",
    "* Two dimensions are compatible if at least one of these is true:\n",
    "    * The dimensions are equal\n",
    "    * One of the dimensions is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de056559-aa8f-46f4-b150-3c6f77fcf1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 12, 13]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor X:                 Scalar Y:\n",
    "torch.tensor([[ 1, 2, 3 ]]) + 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9af0aba3-9740-4a27-9034-4e3a6154e96a",
   "metadata": {},
   "source": [
    "* A 1x3 tensor can be broadcast with a 3x1 tensor, as for each dimension, one of them is 1\n",
    "* The result is a 3x3 tensor\n",
    "\n",
    "|3|x|3|\n",
    "|-|-|-|\n",
    "|3|x|1|\n",
    "|1|x|3|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "418a2a3d-9b24-4067-ae27-ebed81ab9f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 20, 30],\n",
       "        [20, 40, 60],\n",
       "        [30, 60, 90]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1, 2, 3]) * torch.tensor([[10],\n",
    "                                        [20],\n",
    "                                        [30]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0b0a7d-419a-4644-a349-aa008f90b9bc",
   "metadata": {},
   "source": [
    "* For varying dimensionality, the shapes are right-aligned and compared\n",
    "\n",
    "|2|x|2|x|3|\n",
    "|-|-|-|-|-|\n",
    "|2|x|1|x|3|\n",
    "| | |2|x|3|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37e4ea34-352c-4f64-864d-436e8b5027a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[11, 22, 33],\n",
       "         [14, 25, 36]],\n",
       "\n",
       "        [[41, 52, 63],\n",
       "         [44, 55, 66]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "])\n",
    "B = torch.tensor([\n",
    "    [[10, 20, 30]], # Note the extra brackets\n",
    "    [[40, 50, 60]], # This tensor is of shape (2, 1, 3)\n",
    "])\n",
    "\n",
    "A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10f2a43-270f-40c0-b5d2-ff7deae574f2",
   "metadata": {},
   "source": [
    "## Named tensors\n",
    "\n",
    "* Often, the axes of a tensor have distinct meanints, like color channel, or row of pixels\n",
    "* Having to remember these can be highly error-prone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d000f0c7-5462-4daf-b0ca-844e5628cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: image\n",
    "img_t = torch.randn(3, 5, 5) # shape (channel, rows, columns)\n",
    "weights = torch.tensor([0.2126, 0.7152, 0.0722]) # Typical color channel weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46508875-6673-42ea-a73d-aa9139ec4e57",
   "metadata": {},
   "source": [
    "* We often want to generalized, for example from 2D greyscale images to 3D RGB, or from a single image to a batch of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70d6f21b-b07e-45ab-a885-366272a7b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_t = torch.randn(2, 3, 5, 5) # shape (batch, channels, rows, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1214a62-384c-4c6e-bb02-addc22ba4ce2",
   "metadata": {},
   "source": [
    "* Sometimes the RGB channels are in dimension 0, sometimes in dimension 1\n",
    "* They are, however, always -3 from the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f33c0159-7166-4bb7-ad2e-f14940306e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), torch.Size([2, 5, 5]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_naive = img_t.mean(-3)\n",
    "batch_gray_naive = batch_t.mean(-3)\n",
    "img_gray_naive.shape, batch_gray_naive.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7ad5b8-e41e-4524-9625-0ed8b6382ef0",
   "metadata": {},
   "source": [
    "* Things become hard to follow once the weights are added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3eee0090-8964-4b3e-9f0f-f1ab7fc9b12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 5, 5]), torch.Size([2, 3, 5, 5]), torch.Size([3, 1, 1]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze(-1)\n",
    "img_weights = img_t * unsqueezed_weights\n",
    "batch_weights = batch_t * unsqueezed_weights\n",
    "img_gray_weighted = img_weights.sum(-3)\n",
    "batch_gray_weighted = batch_weights.sum(-3)\n",
    "batch_weights.shape, batch_t.shape, unsqueezed_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992c0355-fbf7-4537-a8c8-c322159b0207",
   "metadata": {},
   "source": [
    "* To help with this difficulty, which quickly leads to errors, $named\\ tensors$ were introduced in PyTorch 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5f6f31e-872d-4707-87cd-b5d1bec37a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2126, 0.7152, 0.0722], names=('channels',))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=[\"channels\"])\n",
    "weights_named"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c8b9fc-3b9d-4ca8-b1b8-bbd6ee6b2f61",
   "metadata": {},
   "source": [
    "* With the `refine_names` method, names can be added, without changing existing names\n",
    "* The `rename` method does change existing names, and allows dropping them (by using `None`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f75ee680-10ab-4cca-a6b2-3d01032b958e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img named: torch.Size([3, 5, 5]) ('channels', 'rows', 'columns')\n",
      "batch named: torch.Size([2, 3, 5, 5]) (None, 'channels', 'rows', 'columns')\n"
     ]
    }
   ],
   "source": [
    "# Leading dimensions ignored -> ...\n",
    "img_named =  img_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "batch_named = batch_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "print(\"img named:\", img_named.shape, img_named.names)\n",
    "print(\"batch named:\", batch_named.shape, batch_named.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554a30fd-72e7-4d12-9b11-d141e3d7e430",
   "metadata": {},
   "source": [
    "* Names are now checked during operations between two tensors, in addition to dimensions\n",
    "* To align dimensions, we can use `align_as`, since this is not done automatically yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4aca11c9-1d70-4a20-9278-5ba0473f2118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), ('channels',))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_named.shape, weights_named.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d8ff45b-8053-46dc-a229-cea6a0a87a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1, 1]), ('channels', 'rows', 'columns'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_aligned = weights_named.align_as(img_named)\n",
    "weights_aligned.shape, weights_aligned.names "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50295b9a-8091-482f-a00f-d10645348bda",
   "metadata": {},
   "source": [
    "* The `'rows'` and `'columns'` dimensions are added in their respective positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230b99ad-d359-4df5-b2d5-7cc3f1b5b0d1",
   "metadata": {},
   "source": [
    "* Functions like `sum()`, which accept dimensions, also accept their names as arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55cb4873-9fe8-4c6b-812d-afb44bc2be5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), ('rows', 'columns'))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_named = (img_named * weights_aligned).sum('channels')\n",
    "gray_named.shape, gray_named.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c13b7a1-9892-4224-a336-b51420301630",
   "metadata": {},
   "source": [
    "* Trying to combine dimensions of different names is an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74bbae29-2c4c-4ef2-ba90-b04554416a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when attempting to broadcast dims ['channels', 'rows', 'columns'] and dims ['channels']: dim 'columns' and dim 'channels' are at the same position from the right but do not match.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    gray_named = (img_named[..., :3] * weights_named).sum('channels')\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80606763-5bea-4cee-bc5b-5956e87aee5f",
   "metadata": {},
   "source": [
    "* To continue using tensors outside of functions that operate on named tensors, we can drop their names with `rename`\n",
    "* As named tensors are still experimental (the warning is suppressed in this notebook, so check whether they still are), we will continue with unnamed tensors for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56117380-abac-4bbf-9c0d-94df18a00775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), (None, None))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_plain = gray_named.rename(None)\n",
    "gray_plain.shape, gray_plain.names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
