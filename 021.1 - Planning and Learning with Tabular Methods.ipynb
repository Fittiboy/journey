{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cc45917-ecd1-4145-b9f1-b6bfa35d0cef",
   "metadata": {},
   "source": [
    "# Day 21 - Planning and Learning with Tabular Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11048893-c104-43ac-9805-ee2804eeaad4",
   "metadata": {},
   "source": [
    "## Expected vs. Sample Updates\n",
    "\n",
    "* We have focused on different kinds of value updates, and, limiting our analysis to the one-step case for now, these vary along three binary dimensions:\n",
    "    1. State- vs. action-value\n",
    "    2. Optimal vs. arbitrary policy\n",
    "    3. Expected vs. sample\n",
    "* Seven of the $2^3=8$ possible combinations correspond to specific algorithms:\n",
    "    1. State + Optimal + Expected = Value Iteration\n",
    "    2. State + Arbitrary + Expected = Policy Evaluation\n",
    "    3. State + Arbitrary + Sample = TD(0)\n",
    "    4. Action + Optimal + Expected = Q-Value Iteration\n",
    "    5. Action + Optimal + Sample = Q-Learning\n",
    "    6. Action + Arbitrary + Expected = Q-Policy Evaluation\n",
    "    7. Action + Arbitrary + Sample = Sarsa\n",
    "* Any of these can be used as update rules for planning\n",
    "* When comparing sample updates to expected updates, the question remains whether expected updates are actually to be preferred\n",
    "* While expected updates are exact, not suffering from a sampling error, they are more expensive to compute\n",
    "* Update computation, in practice, is usually dominated by the number of `S, A` pairs at which $Q$ is to be evaluated\n",
    "* If there is enough time for computing an expected update, this more exact estimate is usually preferred\n",
    "* If not, which is usually the case in practice, a sample update is better insofar as it is an actual update, where the expected update would not even get to finish\n",
    "* For large branching factors $b$ (number of possible states reachable from $S$), the error reduction from sampling updates is vastly more compute-efficient, as most of the error reduction comes from the first few samples\n",
    "* An expected update would run $b$ computations per update, which is highly excessive if $b=10,000$, for example\n",
    "* In this case, even $100$ sample updates usually reduce the error significantly\n",
    "* The analysis, from Sutton & Barto, is likely even underestimating the advantage of sample updates, as it does not take into account the fact that the value function becomes more accurate over the course of the updates, which is not the case with expected updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccbcb97-1e21-45f3-9e6e-b0ea6476bea1",
   "metadata": {},
   "source": [
    "### $Exercise\\ \\mathcal{8.6}$\n",
    "\n",
    "#### Exercise 8.6 The analysis above assumed that all of the $b$ possible next states were equally likely to occur. Suppose instead that the distribution was highly skewed, that some of the $b$ states were much more likely to occur than most. Would this strengthen or weaken the case for sample updates over expected updates? Support your answer.\n",
    "\n",
    "If the transition probabilities are highly skewed, the value of a state will be skewed towards the values of the most likely transitions. Unless the rare transitions have such an extreme difference in value, that they compensate for this effect, sample updates will be even more efficient, as they focus copmutation on the most probably successor states. Expected updates spend equal amounts of computation on both likely and highly unlikely transitions, wasting a lot of resources."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
